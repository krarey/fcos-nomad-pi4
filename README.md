# Fedora CoreOS with Nomad on Raspberry Pi 4

This repository contains a basic, opinionated (read: not much error-handling) workflow for generating Fedora CoreOS images configured for the Raspberry Pi 4. This is customized to my particular lab environment, and thus makes the following assumptions:

* The deployment targets are Raspberry Pi 4b SBCs.
* Each node has a USB-attached solid state drive, which will be formatted ext4 and mounted at /var for logs/container image cache/Nomad state/etc.
* Nomad will be run as a scheduler/orchestrator for each node.
* Podman containers will be the primary means of running orchestrated workloads.
* Nodes will be booted via SD card.
* The host building the SD card is running Fedora Linux or a near derivative, with access to `dnf`, the Fedora repositories, and a local Podman installation.
* The host is running aarch64 (I use VMWare Fusion on a MacBook Pro). The build-firmware.sh script may need tweaks to pull the correct packages on x86_64 build hosts.

## Installation

Everything can be run via a Makefile with the following targets:

`nomad.ign`: Launches Butane via Podman to render the Ignition configuration. Will automatically rebuild if changes are made to `nomad.bu`.

`firmware`: Downloads and unpacks RPMs containing the pi4 bootloader and firmware.

`cache`: Downloads a local copy of the latest Fedora CoreOS image, to prevent re-downloading on each run when writing multiple end images.

`install`: Invokes each of the above as a dependency (if not already up-to-date), then uses the `coreos-installer` image via Podman to deploy onto a target device, as defined by teh `TARGET_DEV` variable. Installs the unpacked files from the `firmware` into the resultant boot partition.

`clean`: Cleans up build artifacts from all other targets.

### Usage

For a simple installation, assuming the target SD card is identified on the host as `sda`, just execute the following:

```shell
make install TARGET_DEV=/dev/sda
```

## Nomad

The nodes are pre-configured to pick up the HashiCorp RPM repository, and after first boot will automatically install Nomad as an ostree layered package. Nomad itself could be run as a Podman quadlet generated by Ignition, but for flexibility I chose, for now, to deploy it directly onto the host.

The official RPM package for Nomad uses `/opt/nomad` as the storage path for all stateful data. I prefer strict adherence to FHS where possible (and it makes managing the single SSD mount more convenient), so have created the equivalent directory at `/var/lib/nomad`.

At present, Nomad is not pre-configured by Ignition and the systemd unit is left disabled by default. For the time being I have chosen to continue orchestrating that bit of last-mile config with Ansible, since there are some roles that will vary between nodes while I work on re-architecting my homelab. To complete configuration, one will need to

* Generate a Nomad configuration which takes precedence over the default.
* Configure the Nomad Server and Client roles as desired.
* Configure Nomad to use `/var/lib/nomad` as its `data_dir`.
* Configure ACLs, node pools, additional task drivers, etc. as best fits your use case.

## Future state

Going forward, the following tasks are on the near/mid-term radar:

* Per-node configuration of Nomad upon first boot. Perhaps remote ignition file merges or ansible-pull.
* Implement a Nomad-aware [FleetLock](https://coreos.github.io/zincati/development/fleetlock/protocol/) service to orchestrate Zincati updates.
* CM4 support - I run a separate Turing Pi 2 board. Probably just need to add a serial console config to attach a tty to the UART, handle writing the image out eMMC or a raw file, and things will otherwise Just Workâ„¢.